import streamlit as st
import yaml
import subprocess
import shutil
import requests
import os
import logging
import sys
import urllib.parse
import base64
import re
import json
import platform
from pathlib import Path
from google import genai
from google.genai import types

# Page Config
st.set_page_config(
    page_title="Refactored OpenAPI Validator (v10)",
    page_icon="üìò",
    layout="wide"
)

# --- Initialize Session State for Logs ---
if 'logs' not in st.session_state:
    st.session_state.logs = []

# --- Custom Logging Handler for Streamlit ---
class StreamlitLogHandler(logging.Handler):
    def __init__(self, container, download_placeholder=None):
        super().__init__()
        self.container = container
        self.download_placeholder = download_placeholder

    def emit(self, record):
        msg = self.format(record)
        st.session_state.logs.append(msg)
        self.container.code("\n".join(st.session_state.logs), language="text")
        
        # Update download button dynamically if placeholder exists
        if self.download_placeholder:
            unique_key = f"log_dl_rt_{len(st.session_state.logs)}"
            self.download_placeholder.download_button(
                label="üì• Download Log File",
                data="\n".join(st.session_state.logs),
                file_name="openapi_upload.log",
                mime="text/plain",
                key=unique_key
            )

# --- Helper Functions ---

def get_npx_path():
    # 1. Try standard system path lookup
    path = shutil.which("npx")
    if path:
        return path
    
    # 2. Fallback: Look in the same directory as the Python executable
    # (Common fix for Conda environments where bin/ isn't in PATH)
    try:
        python_dir = os.path.dirname(sys.executable)
        candidate = os.path.join(python_dir, "npx")
        if os.path.exists(candidate):
            return candidate
    except Exception:
        pass
        
    return None

def validate_env(api_key, required=True):
    if not api_key:
        if required:
            st.error("‚ùå ReadMe API Key is missing. Please enter it in the sidebar.")
            st.stop()
        return False
    return True

def run_command(command_list, log_logger):
    try:
        cmd_str = " ".join(command_list)
        log_logger.info(f"Running: {cmd_str}")

        # --- FIX START: Inject Conda Bin Path ---
        # Create a copy of the current environment variables
        env = os.environ.copy()
        
        # If we are calling an executable by full path (like /.../.conda/bin/npx),
        # we must add its directory to PATH so it can find sibling binaries (like 'node').
        executable_path = command_list[0]
        if os.path.isabs(executable_path):
            bin_dir = os.path.dirname(executable_path)
            # Prepend this bin directory to the system PATH
            env["PATH"] = f"{bin_dir}{os.pathsep}{env.get('PATH', '')}"
        # --- FIX END ---

        process = subprocess.Popen(
            command_list,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            env=env  # <--- Important: Pass the modified environment
        )
        
        for line in process.stdout:
            clean = line.strip()
            if clean:
                log_logger.info(f"[CLI] {clean}")
        process.wait()
        return process.returncode
    except Exception as e:
        log_logger.error(f"‚ùå Command failed: {e}")
        return 1

# --- AI Analysis Logic (Google Gen AI SDK) ---
def analyze_errors_with_ai(log_content, api_key, model_name):
    """Sends logs to Google Gen AI for analysis."""
    if not api_key:
        return None
    
    try:
        client = genai.Client(api_key=api_key)
        
        prompt = f"""
        You are an expert OpenAPI Validator. Analyze the following log output from a CI/CD pipeline. 
        It contains errors from Swagger CLI, Redocly CLI, or ReadMe CLI (rdme v10).
        
        Identify the specific YAML errors (like trailing slashes, missing references, schema issues) 
        and provide actionable solutions (code snippets) for the user to fix their OpenAPI YAML file.
        
        Keep it concise, professional, and use Markdown formatting.
        
        Logs:
        {log_content}
        """
        
        response = client.models.generate_content(
            model=model_name,
            contents=[prompt]
        )
        
        return response.text
    except Exception as e:
        return f"Exception calling AI: {e}"

# --- Git Logic ---

def setup_git_repo(repo_url, repo_dir, git_token, git_username, branch_name, logger):
    logger.info(f"üöÄ Starting Git Operation for branch: {branch_name}...")
    
    repo_path = Path(repo_dir)
    # Clean inputs
    if repo_url:
        repo_url = repo_url.strip().strip('"').strip("'")
    if git_username:
        git_username = git_username.strip().strip('"').strip("'")
    if git_token:
        git_token = git_token.strip().strip('"').strip("'")

    # Clean URL Logic (Handle copy-paste errors)
    if repo_url and repo_url.count("https://") > 1:
        match = re.search(r"(https://github\.com/.*)$", repo_url)
        if match:
            repo_url = match.group(1)

    auth_repo_url = repo_url
    masked_repo_url = repo_url

    try:
        if repo_url:
            parsed = urllib.parse.urlparse(repo_url)
            # Only embed auth if token/user provided
            if git_username and git_token:
                safe_user = urllib.parse.quote(git_username, safe='')
                safe_token = urllib.parse.quote(git_token, safe='')
                
                if "@" in parsed.netloc:
                    clean_netloc = parsed.netloc.split("@")[-1]
                else:
                    clean_netloc = parsed.netloc

                auth_netloc = f"{safe_user}:{safe_token}@{clean_netloc}"
                auth_repo_url = urllib.parse.urlunparse((
                    parsed.scheme, auth_netloc, parsed.path, parsed.params, parsed.query, parsed.fragment
                ))
                masked_netloc = f"****:***@{clean_netloc}"
                masked_repo_url = urllib.parse.urlunparse((
                    parsed.scheme, masked_netloc, parsed.path, parsed.params, parsed.query, parsed.fragment
                ))
        
    except Exception as e:
        logger.error(f"‚ùå URL Construction Failed: {e}")
        st.stop()

    clean_env = os.environ.copy()
    null_path = "NUL" if platform.system() == "Windows" else "/dev/null"
    clean_env["GIT_CONFIG_GLOBAL"] = null_path
    clean_env["GIT_CONFIG_SYSTEM"] = null_path
    clean_env["GIT_TERMINAL_PROMPT"] = "0"

    git_args = ["-c", "core.askPass=echo"] 

    if not repo_path.exists():
        # --- CLONE NEW REPO ---
        logger.info(f"‚¨áÔ∏è Cloning branch '{branch_name}' from: {masked_repo_url}")
        try:
            cmd = ["git"] + git_args + ["clone", "--depth", "1", "--branch", branch_name, auth_repo_url, str(repo_path)]
            result = subprocess.run(cmd, capture_output=True, text=True, env=clean_env)
            
            if result.returncode != 0:
                sso_match = re.search(r"(https://github\.com/orgs/[^/]+/sso\?authorization_request=[^\s]+)", result.stderr)
                if sso_match:
                    sso_url = sso_match.group(1)
                    logger.error("‚ùå SSO AUTHORIZATION REQUIRED")
                    st.error("üö® Organization requires SAML SSO Authorization.")
                    st.markdown(f"üëâ **[Click here to Authorize your Token]({sso_url})**")
                    st.stop()
                elif "403" in result.stderr:
                    st.error("üö® Authentication Failed (403).")
                    st.info("Ensure your Token has 'repo' scope and SSO is configured.")
                    st.stop()
                else:
                    safe_err = result.stderr.replace(git_token, "***").replace(git_username, "****") if git_token else result.stderr
                    logger.error(f"‚ùå Git Output:\n{safe_err}")
                    st.error(f"Git Clone Failed for branch '{branch_name}'. Check if branch exists.")
                    st.stop()
            else:
                logger.info("‚úÖ Repo cloned successfully.")
        except Exception as e:
            logger.error(f"‚ùå System Error: {e}")
            st.stop()
    else:
        # --- UPDATE EXISTING REPO ---
        logger.info(f"üîÑ Switching/Updating to branch '{branch_name}'...")
        try:
            # 1. Update Remote URL (in case tokens changed)
            subprocess.run(["git", "-C", str(repo_path), "remote", "set-url", "origin", auth_repo_url], 
                         check=True, capture_output=True, env=clean_env)
            
            # 2. Fetch the specific branch
            subprocess.run(["git", "-C", str(repo_path), "fetch", "origin", branch_name],
                         check=True, capture_output=True, env=clean_env)

            # 3. Checkout the branch (force reset to match remote)
            subprocess.run(["git", "-C", str(repo_path), "reset", "--hard", f"origin/{branch_name}"],
                         check=True, capture_output=True, env=clean_env)
            
            logger.info(f"‚úÖ Successfully switched to '{branch_name}'.")
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Git Operation failed: {e}")
            logger.warning("‚ö†Ô∏è Attempting to continue with current files (might be outdated)...")

def delete_repo(repo_dir):
    path = Path(repo_dir)
    if path.exists():
        try:
            shutil.rmtree(path)
            return True, "Deleted successfully."
        except Exception as e:
            return False, f"Error deleting: {e}"
    return False, "Path does not exist."

# --- File Operations ---

def prepare_files(filename, paths, workspace, dependency_list, logger):
    """
    Locates the selected file, copies it to workspace, and copies dependencies.
    """
    source = None
    
    # 1. Search in Main Specs Path
    main_candidate = Path(paths['specs']) / f"{filename}.yaml"
    if main_candidate.exists():
        source = main_candidate
    
    # 2. Search in Secondary Path (if configured)
    elif paths.get('secondary') and (Path(paths['secondary']) / f"{filename}.yaml").exists():
        source = Path(paths['secondary']) / f"{filename}.yaml"

    if not source:
        logger.error(f"‚ùå Source file '{filename}.yaml' not found.")
        logger.info(f"‚ÑπÔ∏è Searched in: {paths['specs']}")
        if paths.get('secondary'):
            logger.info(f"‚ÑπÔ∏è Searched in: {paths['secondary']}")
        st.stop()

    workspace_path = Path(workspace)
    workspace_path.mkdir(parents=True, exist_ok=True)
    destination = workspace_path / source.name
    shutil.copy(source, destination)
    logger.info(f"üìÇ Copied main YAML to workspace: {destination.name}")

    # 3. Copy Dependencies (Generic List)
    for folder in dependency_list:
        clean_folder = folder.strip()
        if not clean_folder: continue
        
        src_folder = Path(paths['specs']) / clean_folder
        dest_folder = workspace_path / clean_folder
        
        if src_folder.exists():
            if dest_folder.exists():
                shutil.rmtree(dest_folder)
            shutil.copytree(src_folder, dest_folder)
            logger.info(f"üìÇ Copied dependency folder: {clean_folder}")
        else:
            logger.warning(f"‚ö†Ô∏è Dependency folder not found: {src_folder}")

    return destination

def process_yaml_content(file_path, api_domain, logger):
    """
    Injects ReadMe extensions and updates server URL with user-defined domain.
    In Refactored, versioning is handled by the branch, but we still update servers.
    """
    logger.info("üõ†Ô∏è Injecting x-readme extensions and updating server info...")
    try:
        with open(file_path, "r") as f:
            data = yaml.safe_load(f)

        # Inject x-readme
        if "openapi" in data:
            pos = list(data.keys()).index("openapi")
            items = list(data.items())
            items.insert(pos + 1, ("x-readme", {"explorer-enabled": False}))
            data = dict(items)
        
        # Use user-provided domain or default
        domain = api_domain if api_domain else "example.com"
        
        if "servers" not in data or not data["servers"]:
            data["servers"] = [{"url": f"https://{domain}", "variables": {}}]

        if "variables" not in data["servers"][0]:
            data["servers"][0]["variables"] = {}
            
        data["servers"][0]["variables"]["base-url"] = {"default": domain}
        data["servers"][0]["variables"]["protocol"] = {"default": "https"}

        edited_path = file_path.parent / (file_path.stem + "_edited.yaml")
        with open(edited_path, "w") as f:
            yaml.dump(data, f, sort_keys=False)
        logger.info(f"üìù Edited YAML saved to: {edited_path.name}")
        return edited_path
    except Exception as e:
        logger.error(f"‚ùå Error processing YAML: {e}")
        st.stop()

# --- CALLBACK FUNCTIONS ---
def clear_credentials():
    """Clears session state variables."""
    st.session_state.readme_key = ""
    st.session_state.git_user = ""
    st.session_state.git_token = ""
    st.session_state.gemini_key = ""
    st.session_state.logs = []

def clear_logs():
    """Clears the log history."""
    st.session_state.logs = []

# --- UI Layout ---

def main():
    st.sidebar.title("‚öôÔ∏è Refactored Config")
    
    # --- CREDENTIAL MANAGEMENT ---
    if 'readme_key' not in st.session_state: st.session_state.readme_key = ""
    if 'gemini_key' not in st.session_state: st.session_state.gemini_key = ""
    if 'git_user' not in st.session_state: st.session_state.git_user = ""
    if 'git_token' not in st.session_state: st.session_state.git_token = ""
    if 'repo_url' not in st.session_state: st.session_state.repo_url = ""
    if 'last_edited_file' not in st.session_state: st.session_state.last_edited_file = None
    
    if 'ai_model' not in st.session_state: st.session_state.ai_model = "gemini-2.0-flash"

    readme_key = st.sidebar.text_input("ReadMe API Key", key="readme_key", type="password", help="Required. Use the 'rdme_...' key from dashboard.")
    
    with st.sidebar.expander("ü§ñ AI Configuration", expanded=True):
        gemini_key = st.text_input("Gemini API Key", key="gemini_key", type="password", help="Required for AI Analysis")
        ai_model = st.text_input("Model Name", key="ai_model", value="gemini-2.0-flash")
    
    st.sidebar.subheader("Git Repo Config")
    default_cloud_path = "./cloned_repo"
    repo_path = st.sidebar.text_input("Local Clone Path", value=default_cloud_path)
    
    if st.sidebar.button("üóëÔ∏è Reset / Delete Cloned Repo"):
        success, msg = delete_repo(repo_path)
        if success: st.sidebar.success(msg)
        else: st.sidebar.warning(msg)
    
    repo_url = st.sidebar.text_input("Git Repo HTTPS URL", key="repo_url")
    branch_name = st.sidebar.text_input("Git Branch Source", value="main", help="Branch to pull YAML files FROM")

    git_user = st.sidebar.text_input("Git Username", key="git_user", type="password", help="GitHub Handle")
    git_token = st.sidebar.text_input("Git Token/PAT", key="git_token", type="password", help="Personal Access Token")

    st.sidebar.button("üîí Clear Credentials", on_click=clear_credentials)

    # --- INTERNAL PATHS & SETTINGS ---
    st.sidebar.subheader("Internal Paths & Settings")
    spec_rel_path = st.sidebar.text_input("Main Specs Path (relative to repo)", value="specs", help="Folder containing your main OpenAPI files.") 
    secondary_rel_path = st.sidebar.text_input("Secondary Specs Path (Optional)", value="", help="Another folder to scan for YAML files.")
    dep_input = st.sidebar.text_input("Dependency Folders", value="common", help="Comma-separated list of folders to copy.")
    dependency_list = [x.strip() for x in dep_input.split(",")]
    api_domain = st.sidebar.text_input("API Base Domain", value="api.example.com", help="Domain to inject into servers.url")

    # Path Setup
    abs_spec_path = Path(repo_path) / spec_rel_path
    paths = {"repo": repo_path, "specs": abs_spec_path}
    if secondary_rel_path:
        paths["secondary"] = Path(repo_path) / secondary_rel_path
    workspace_dir = "./temp_workspace"

    st.title("üöÄ Refactored OpenAPI Validator")
    
    # --- FILE SELECTION ---
    col1, col2 = st.columns(2)
    with col1:
        files = []
        if abs_spec_path.exists():
            files.extend([f.stem for f in abs_spec_path.glob("*.yaml")])
        if "secondary" in paths and paths["secondary"].exists():
            files.extend([f.stem for f in paths["secondary"].glob("*.yaml")])
        files = sorted(list(set(files)))
        
        if files:
            selected_file = st.selectbox("Select OpenAPI File", files)
        else:
            selected_file = st.text_input("Enter Filename (e.g. 'audit')", "audit")
            if not abs_spec_path.exists():
                st.warning(f"‚ö†Ô∏è Repo not synced yet. Click 'Validate' to clone branch '{branch_name}'.")

    with col2:
        # CHANGED: Replaced "Version" with "Target Branch" for Refactored workflow
        target_branch = st.text_input("Target ReadMe Branch", "main", help="Where to upload this spec (e.g., 'main' or 'staging').")

    # --- CHECKBOX UI ---
    st.markdown("### üöÄ Validation Settings")
    c_check1, c_check2, c_check3 = st.columns(3)
    with c_check1: use_swagger = st.checkbox("Swagger CLI", value=True)
    with c_check2: use_redocly = st.checkbox("Redocly CLI", value=True)
    with c_check3: use_readme = st.checkbox("ReadMe CLI (v10)", value=False, help="Requires ReadMe API Key")
    
    st.markdown("---")
    
    c_btn1, c_btn2 = st.columns(2)
    btn_validate_selected = c_btn1.button("üîç Validate Selected", use_container_width=True)
    btn_upload = c_btn2.button("üöÄ Upload to ReadMe", type="primary", use_container_width=True)

    # --- 1. SETUP UI LAYOUT (Must happen BEFORE logic) ---
    st.markdown("### üìú Execution Logs")
    
    # Container for log text
    log_container = st.empty()
    if st.session_state.logs:
        log_container.code("\n".join(st.session_state.logs), language="text")

    # Columns for Buttons
    col_d1, col_d2, col_d3 = st.columns([1, 1, 3])
    
    # Placeholder for Live Download Button (Managed by Handler)
    with col_d1:
        download_placeholder = st.empty()
        # Restore download button if logs exist (persistence)
        if st.session_state.logs:
            unique_key = f"dl_btn_persist_{len(st.session_state.logs)}"
            download_placeholder.download_button(
                label="üì• Download Logs",
                data="\n".join(st.session_state.logs),
                file_name="openapi_upload.log",
                mime="text/plain",
                key=unique_key
            )

    # --- 2. EXECUTION LOGIC ---
    if btn_validate_selected or btn_upload:
        st.session_state.logs = [] 
        st.session_state.last_edited_file = None
        
        logger = logging.getLogger("streamlit_logger")
        logger.setLevel(logging.INFO)
        if logger.handlers: logger.handlers = []
        handler = StreamlitLogHandler(log_container, download_placeholder)
        handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S'))
        logger.addHandler(handler)

        strict_key_req = True if btn_upload else False
        has_key = validate_env(readme_key, required=strict_key_req)
        
        npx_path = get_npx_path()
        if not npx_path:
            logger.error("‚ùå NodeJS/npx not found.")
            st.stop()

        # GIT CALL
        setup_git_repo(repo_url, repo_path, git_token, git_user, branch_name, logger)

        logger.info("üìÇ Preparing workspace...")
        final_yaml_path = prepare_files(selected_file, paths, workspace_dir, dependency_list, logger)

        # PROCESS & STORE EDITED FILE
        edited_file = process_yaml_content(final_yaml_path, api_domain, logger)
        st.session_state.last_edited_file = str(edited_file)

        # Validation Logic
        if btn_upload:
            do_swagger = True
            do_redocly = False
            do_readme = True
        else:
            do_swagger = use_swagger
            do_redocly = use_redocly
            do_readme = use_readme

        validation_failed = False
        
        # 1. SWAGGER
        if do_swagger:
            logger.info("üîç Running Swagger CLI...")
            if run_command([npx_path, "--yes", "swagger-cli", "validate", str(edited_file)], logger) != 0: 
                validation_failed = True
        
        # 2. REDOCLY
        if do_redocly:
            logger.info("üîç Running Redocly CLI...")
            if run_command([npx_path, "--yes", "@redocly/cli@1.25.0", "lint", str(edited_file)], logger) != 0: 
                validation_failed = True
            
        # 3. README (Updated for Refactored v10)
        if do_readme:
            if has_key:
                logger.info("üîç Running ReadMe CLI (openapi:validate)...")
                # V10 Command: rdme openapi:validate <file>
                if run_command([npx_path, "--yes", "rdme", "openapi:validate", str(edited_file)], logger) != 0: 
                    validation_failed = True
            else:
                logger.warning("‚ö†Ô∏è Skipping ReadMe CLI validation (Key missing).")

        # RESULT
        if validation_failed:
            logger.error("‚ùå Validation failed.")
            st.error("Validation Failed.")
            if btn_upload: st.error("Aborting upload.")
        else:
            logger.info("‚úÖ Selected validations passed.")
            if btn_upload:
                logger.info(f"üöÄ Uploading to ReadMe Branch: {target_branch}...")
                
                # V10 Upload Command: rdme openapi upload <file> --key <key> --branch <branch>
                cmd = [
                    npx_path, "--yes", "rdme", "openapi", "upload", str(edited_file),
                    "--key", readme_key,
                    "--branch", target_branch
                ]
                
                if run_command(cmd, logger) == 0:
                    logger.info("üéâ Upload Successful!")
                    st.success(f"Done! Spec uploaded to branch '{target_branch}'.")
                else:
                    logger.error("‚ùå Upload failed.")
            else:
                st.success("Validation Check Complete.")

    # --- 3. POST-EXECUTION UI RENDERING ---
    # Now that logic is done and session_state is updated, render the buttons
    
    # YAML Download Button
    with col_d2:
        if 'last_edited_file' in st.session_state and st.session_state.last_edited_file:
            edited_path = Path(st.session_state.last_edited_file)
            if edited_path.exists():
                with open(edited_path, "r") as f:
                    yaml_content = f.read()
                
                st.download_button(
                    label="üìÑ Download Edited YAML",
                    data=yaml_content,
                    file_name=edited_path.name,
                    mime="application/x-yaml",
                    key="dl_yaml_btn"
                )

    # Clear Logs Button
    with col_d3:
        if st.session_state.logs:
             st.button("üóëÔ∏è Clear Logs", on_click=clear_logs)

    # AI Analysis Section
    if st.session_state.logs and gemini_key:
        if st.button(f"ü§ñ Analyze Logs with {ai_model}"):
            with st.spinner("Analyzing errors..."):
                log_text = "\n".join(st.session_state.logs)
                analysis = analyze_errors_with_ai(log_text, gemini_key, ai_model)
                if analysis:
                    st.markdown("### ü§ñ AI Fix Suggestion")
                    st.markdown(analysis)
    elif st.session_state.logs and not gemini_key:
        st.info("üí° Enter a Gemini API Key in the sidebar to unlock error analysis.")

if __name__ == "__main__":
    main()
